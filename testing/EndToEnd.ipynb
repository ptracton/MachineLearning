{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the Problem\n",
    "\n",
    "1. Define the objective in business terms.  \n",
    "2. How will your solution be used?  \n",
    "3. What are the current solutions/workarounds (if any)?  \n",
    "4. How should you frame this problem (supervised/unsupervised, online/offline, etc.)  \n",
    "5. How should performance be measured?  \n",
    "6. Is the performance measure aligned with the business objective?  \n",
    "7. What would be the minimum performance needed to reach the business objective?  \n",
    "8. What are comparable problems? Can you reuse experience or tools?  \n",
    "9. Is human expertise available?  \n",
    "10. How would you solve the problem manually?  \n",
    "11. List the assumptions you or others have made so far.  \n",
    "12. Verify assumptions if possible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a learning exercise in carrying through the entire process of a Machine Learning question. The plan is to use data from https://www.openml.org/d/1471, this is the data set from https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State#.  \n",
    "\n",
    "All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analyzing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data.\n",
    "\n",
    "The features correspond to 14 EEG measurements from the headset, originally labeled AF3, F7, F3, FC5, T7, P, O1, O2, P8, T8, FC6, F4, F8, AF4, in that order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data\n",
    "Note: automate as much as possible so you can easily get fresh data.  \n",
    "\n",
    "1. List the data you need and how much you need.  \n",
    "2. Find and document where you can get that data.  \n",
    "3. Check how much space it will take.  \n",
    "4. Check legal obligations, and get the authorization if necessary.  \n",
    "5. Get access authorizations.  \n",
    "6. Create a workspace (with enough storage space).  \n",
    "7. Get the data.  \n",
    "8. Convert the data to a format you can easily manipulate (without changing the data itself).  \n",
    "9. Ensure sensitive information is deleted or protected (e.g., anonymized). \n",
    "10. Check the size and type of data (time series, sample, geographical, etc.).  \n",
    "11. Sample a test set, put it aside, and never look at it (no data snooping!).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(\"eeg-eye-state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[4329.23, 4009.23, 4289.23, ..., 4280.51, 4635.9 , 4393.85],\n",
      "       [4324.62, 4004.62, 4293.85, ..., 4279.49, 4632.82, 4384.1 ],\n",
      "       [4327.69, 4006.67, 4295.38, ..., 4282.05, 4628.72, 4389.23],\n",
      "       ...,\n",
      "       [4277.44, 3990.77, 4246.67, ..., 4257.95, 4591.79, 4339.49],\n",
      "       [4284.62, 3991.79, 4251.28, ..., 4267.18, 4596.41, 4350.77],\n",
      "       [4287.69, 3997.44, 4260.  , ..., 4274.36, 4597.95, 4350.77]]), 'target': array(['1', '1', '1', ..., '2', '2', '2'], dtype=object), 'frame': None, 'feature_names': ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14'], 'target_names': ['Class'], 'DESCR': \"**Author**: Oliver Roesler  \\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State), Baden-Wuerttemberg, Cooperative State University (DHBW), Stuttgart, Germany  \\n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  \\n\\nAll data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analyzing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data.\\n\\nThe features correspond to 14 EEG measurements from the headset, originally labeled AF3, F7, F3, FC5, T7, P, O1, O2, P8, T8, FC6, F4, F8, AF4, in that order.\\n\\nDownloaded from openml.org.\", 'details': {'id': '1471', 'name': 'eeg-eye-state', 'version': '1', 'format': 'ARFF', 'upload_date': '2015-05-22T16:40:04', 'licence': 'Public', 'url': 'https://www.openml.org/data/v1/download/1587924/eeg-eye-state.arff', 'file_id': '1587924', 'default_target_attribute': 'Class', 'tag': ['brain', 'EEG', 'OpenML100', 'study_123', 'study_14', 'study_34', 'study_7', 'time_series', 'uci'], 'visibility': 'public', 'status': 'active', 'processing_date': '2019-07-09 15:20:53', 'md5_checksum': '32086b7bec4daaa9cbe5f19efa63368c'}, 'categories': {}, 'url': 'https://www.openml.org/d/1471'}\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "feature_names = data['feature_names']\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4329.23, 4009.23, 4289.23, 4148.21, 4350.26, 4586.15, 4096.92, 4641.03, 4222.05, 4238.46, 4211.28, 4280.51, 4635.9 , 4393.85, b'1')\n",
      " (4324.62, 4004.62, 4293.85, 4148.72, 4342.05, 4586.67, 4097.44, 4638.97, 4210.77, 4226.67, 4207.69, 4279.49, 4632.82, 4384.1 , b'1')\n",
      " (4327.69, 4006.67, 4295.38, 4156.41, 4336.92, 4583.59, 4096.92, 4630.26, 4207.69, 4222.05, 4206.67, 4282.05, 4628.72, 4389.23, b'1')\n",
      " ...\n",
      " (4277.44, 3990.77, 4246.67, 4113.85, 4333.33, 4615.38, 4072.82, 4623.59, 4193.33, 4212.82, 4160.51, 4257.95, 4591.79, 4339.49, b'2')\n",
      " (4284.62, 3991.79, 4251.28, 4122.05, 4334.36, 4616.41, 4080.51, 4628.72, 4200.  , 4220.  , 4165.64, 4267.18, 4596.41, 4350.77, b'2')\n",
      " (4287.69, 3997.44, 4260.  , 4121.03, 4333.33, 4616.41, 4088.72, 4638.46, 4212.31, 4226.67, 4167.69, 4274.36, 4597.95, 4350.77, b'2')]\n",
      "Dataset: eeg-eye-state\n",
      "\tV1's type is numeric\n",
      "\tV2's type is numeric\n",
      "\tV3's type is numeric\n",
      "\tV4's type is numeric\n",
      "\tV5's type is numeric\n",
      "\tV6's type is numeric\n",
      "\tV7's type is numeric\n",
      "\tV8's type is numeric\n",
      "\tV9's type is numeric\n",
      "\tV10's type is numeric\n",
      "\tV11's type is numeric\n",
      "\tV12's type is numeric\n",
      "\tV13's type is numeric\n",
      "\tV14's type is numeric\n",
      "\tClass's type is nominal, range is ('1', '2')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "data, meta = arff.loadarff(\"eeg-eye-state.arff\")\n",
    "print(data)\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        V1       V2       V3       V4       V5       V6       V7       V8  \\\n",
      "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
      "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
      "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
      "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
      "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
      "\n",
      "        V9      V10      V11      V12      V13      V14  Class  \n",
      "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85      1  \n",
      "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10      1  \n",
      "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23      1  \n",
      "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41      1  \n",
      "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46      1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14980 entries, 0 to 14979\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V1      14980 non-null  float64\n",
      " 1   V2      14980 non-null  float64\n",
      " 2   V3      14980 non-null  float64\n",
      " 3   V4      14980 non-null  float64\n",
      " 4   V5      14980 non-null  float64\n",
      " 5   V6      14980 non-null  float64\n",
      " 6   V7      14980 non-null  float64\n",
      " 7   V8      14980 non-null  float64\n",
      " 8   V9      14980 non-null  float64\n",
      " 9   V10     14980 non-null  float64\n",
      " 10  V11     14980 non-null  float64\n",
      " 11  V12     14980 non-null  float64\n",
      " 12  V13     14980 non-null  float64\n",
      " 13  V14     14980 non-null  float64\n",
      " 14  Class   14980 non-null  int64  \n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 1.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"eeg-eye-state.csv\")\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into  test/training\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>4210.26</td>\n",
       "      <td>3956.92</td>\n",
       "      <td>4218.97</td>\n",
       "      <td>4098.97</td>\n",
       "      <td>4334.87</td>\n",
       "      <td>4618.46</td>\n",
       "      <td>4083.08</td>\n",
       "      <td>4612.31</td>\n",
       "      <td>4201.03</td>\n",
       "      <td>4209.74</td>\n",
       "      <td>4165.13</td>\n",
       "      <td>4245.64</td>\n",
       "      <td>4533.85</td>\n",
       "      <td>4273.33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>4308.21</td>\n",
       "      <td>4002.05</td>\n",
       "      <td>4260.00</td>\n",
       "      <td>4130.26</td>\n",
       "      <td>4345.13</td>\n",
       "      <td>4607.69</td>\n",
       "      <td>4082.05</td>\n",
       "      <td>4626.15</td>\n",
       "      <td>4208.21</td>\n",
       "      <td>4231.28</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4278.46</td>\n",
       "      <td>4617.44</td>\n",
       "      <td>4362.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10317</th>\n",
       "      <td>4289.74</td>\n",
       "      <td>4002.56</td>\n",
       "      <td>4261.54</td>\n",
       "      <td>4123.59</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4629.23</td>\n",
       "      <td>4060.00</td>\n",
       "      <td>4615.38</td>\n",
       "      <td>4208.21</td>\n",
       "      <td>4234.36</td>\n",
       "      <td>4201.54</td>\n",
       "      <td>4272.31</td>\n",
       "      <td>4594.87</td>\n",
       "      <td>4334.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>4334.87</td>\n",
       "      <td>3986.15</td>\n",
       "      <td>4263.59</td>\n",
       "      <td>4103.59</td>\n",
       "      <td>4333.33</td>\n",
       "      <td>4631.79</td>\n",
       "      <td>4108.21</td>\n",
       "      <td>4631.28</td>\n",
       "      <td>4223.59</td>\n",
       "      <td>4231.28</td>\n",
       "      <td>4191.28</td>\n",
       "      <td>4301.54</td>\n",
       "      <td>4617.44</td>\n",
       "      <td>4391.28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9029</th>\n",
       "      <td>4217.44</td>\n",
       "      <td>3986.15</td>\n",
       "      <td>4223.59</td>\n",
       "      <td>4083.59</td>\n",
       "      <td>4332.31</td>\n",
       "      <td>4614.87</td>\n",
       "      <td>4066.15</td>\n",
       "      <td>4609.74</td>\n",
       "      <td>4170.77</td>\n",
       "      <td>4203.08</td>\n",
       "      <td>4152.82</td>\n",
       "      <td>4242.05</td>\n",
       "      <td>4522.56</td>\n",
       "      <td>4249.74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1       V2       V3       V4       V5       V6       V7       V8  \\\n",
       "2631   4210.26  3956.92  4218.97  4098.97  4334.87  4618.46  4083.08  4612.31   \n",
       "107    4308.21  4002.05  4260.00  4130.26  4345.13  4607.69  4082.05  4626.15   \n",
       "10317  4289.74  4002.56  4261.54  4123.59  4336.92  4629.23  4060.00  4615.38   \n",
       "367    4334.87  3986.15  4263.59  4103.59  4333.33  4631.79  4108.21  4631.28   \n",
       "9029   4217.44  3986.15  4223.59  4083.59  4332.31  4614.87  4066.15  4609.74   \n",
       "\n",
       "            V9      V10      V11      V12      V13      V14  Class  \n",
       "2631   4201.03  4209.74  4165.13  4245.64  4533.85  4273.33      2  \n",
       "107    4208.21  4231.28  4210.77  4278.46  4617.44  4362.56      1  \n",
       "10317  4208.21  4234.36  4201.54  4272.31  4594.87  4334.87      1  \n",
       "367    4223.59  4231.28  4191.28  4301.54  4617.44  4391.28      2  \n",
       "9029   4170.77  4203.08  4152.82  4242.05  4522.56  4249.74      2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Note: try to get insights from a field expert for these steps.  \n",
    "\n",
    "1. Create a copy of the data for exploration (sampling it down to a manageable size if necessary).\n",
    "2. Create a Jupyter notebook to keep record of your data exploration.  \n",
    "3. Study each attribute and its characteristics:  \n",
    "    - Name  \n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.)\n",
    "    - % of missing values  \n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n",
    "    - Possibly useful for the task?  \n",
    "    - Type of distribution (Gaussian, uniform, logarithmic, etc.)\n",
    "4. For supervised learning tasks, identify the target attribute(s).\n",
    "5. Visualize the data.  \n",
    "6. Study the correlations between attributes.  \n",
    "7. Study how you would solve the problem manually.  \n",
    "8. Identify the promising transformations you may want to apply.  \n",
    "9. Identify extra data that would be useful (go back to \"Get the Data\" on page 502).  \n",
    "10. Document what you have learned.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_original = train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bc29d68>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bc64fd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bc0a208>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bbbb470>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bb706d8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bba5940>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bb58ba8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bb0cdd8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8bb0ce48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8ba7f320>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8ba35588>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8b9e77f0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8ba1ba58>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8b9cecc0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8b98f240>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8b9405c0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_set.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a956278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a906828>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a934a58>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a8ebcc0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a89df28>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a85e1d0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a810438>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a7c4668>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f1e8a7c46d8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "attributes = [\"V10\", \"V2\", \"V3\"]\n",
    "scatter_matrix(train_set[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare the Data\n",
    "Notes:    \n",
    "- Work on copies of the data (keep the original dataset intact).  \n",
    "- Write functions for all data transformations you apply, for five reasons:  \n",
    "    - So you can easily prepare the data the next time you get a fresh dataset  \n",
    "    - So you can apply these transformations in future projects  \n",
    "    - To clean and prepare the test set  \n",
    "    - To clean and prepare new data instances  \n",
    "    - To make it easy to treat your preparation choices as hyperparameters  \n",
    "\n",
    "1. Data cleaning:  \n",
    "    - Fix or remove outliers (optional).  \n",
    "    - Fill in missing values (e.g., with zero, mean, median...) or drop their rows (or columns).  \n",
    "2. Feature selection (optional):  \n",
    "    - Drop the attributes that provide no useful information for the task.  \n",
    "3. Feature engineering, where appropriates:  \n",
    "    - Discretize continuous features.  \n",
    "    - Decompose features (e.g., categorical, date/time, etc.).  \n",
    "    - Add promising transformations of features (e.g., log(x), sqrt(x), x^2, etc.).\n",
    "    - Aggregate features into promising new features.  \n",
    "4. Feature scaling: standardize or normalize features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Explore Models\n",
    "Notes: \n",
    "- If the data is huge, you may want to sample smaller training sets so you can train many different models in a reasonable time (be aware that this penalizes complex models such as large neural nets or Random Forests).  \n",
    "- Once again, try to automate these steps as much as possible.    \n",
    "\n",
    "1. Train many quick and dirty models from different categories (e.g., linear, naive, Bayes, SVM, Random Forests, neural net, etc.) using standard parameters.  \n",
    "2. Measure and compare their performance.  \n",
    "    - For each model, use N-fold cross-validation and compute the mean and standard deviation of their performance. \n",
    "3. Analyze the most significant variables for each algorithm.  \n",
    "4. Analyze the types of errors the models make.  \n",
    "    - What data would a human have used to avoid these errors?  \n",
    "5. Have a quick round of feature selection and engineering.  \n",
    "6. Have one or two more quick iterations of the five previous steps.  \n",
    "7. Short-list the top three to five most promising models, preferring models that make different types of errors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2631     2\n",
      "107      1\n",
      "10317    1\n",
      "367      2\n",
      "9029     2\n",
      "        ..\n",
      "5191     1\n",
      "13418    1\n",
      "5390     2\n",
      "860      2\n",
      "7270     2\n",
      "Name: Class, Length: 11984, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y=train_set.Class\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1       V2       V3       V4       V5       V6       V7       V8  \\\n",
      "2631   4210.26  3956.92  4218.97  4098.97  4334.87  4618.46  4083.08  4612.31   \n",
      "107    4308.21  4002.05  4260.00  4130.26  4345.13  4607.69  4082.05  4626.15   \n",
      "10317  4289.74  4002.56  4261.54  4123.59  4336.92  4629.23  4060.00  4615.38   \n",
      "367    4334.87  3986.15  4263.59  4103.59  4333.33  4631.79  4108.21  4631.28   \n",
      "9029   4217.44  3986.15  4223.59  4083.59  4332.31  4614.87  4066.15  4609.74   \n",
      "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "5191   4320.00  4010.77  4258.46  4121.54  4336.41  4620.51  4065.13  4597.95   \n",
      "13418  4284.62  4021.03  4264.62  4151.79  4350.26  4618.97  4060.00  4607.69   \n",
      "5390   4330.77  3990.26  4287.18  4121.03  4340.00  4614.87  4089.74  4610.77   \n",
      "860    4267.69  4025.13  4254.87  4136.41  4343.59  4620.51  4110.26  4606.67   \n",
      "7270   4277.95  3986.67  4244.62  4109.74  4329.74  4608.72  4054.87  4610.77   \n",
      "\n",
      "            V9      V10      V11      V12      V13      V14  \n",
      "2631   4201.03  4209.74  4165.13  4245.64  4533.85  4273.33  \n",
      "107    4208.21  4231.28  4210.77  4278.46  4617.44  4362.56  \n",
      "10317  4208.21  4234.36  4201.54  4272.31  4594.87  4334.87  \n",
      "367    4223.59  4231.28  4191.28  4301.54  4617.44  4391.28  \n",
      "9029   4170.77  4203.08  4152.82  4242.05  4522.56  4249.74  \n",
      "...        ...      ...      ...      ...      ...      ...  \n",
      "5191   4197.95  4251.79  4203.59  4280.51  4613.33  4381.03  \n",
      "13418  4190.77  4209.74  4193.33  4259.49  4591.28  4343.08  \n",
      "5390   4204.62  4252.31  4219.49  4304.62  4626.15  4393.33  \n",
      "860    4207.69  4213.33  4175.90  4270.26  4549.74  4312.82  \n",
      "7270   4193.33  4218.97  4204.10  4261.03  4589.74  4338.46  \n",
      "\n",
      "[11984 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "X = train_set.drop(columns=\"Class\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47392717149528507"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictions = lin_reg.predict(X)\n",
    "lin_mse = mean_squared_error(y, predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4502689257540642"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(y, predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=42, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tree_reg.predict(X)\n",
    "tree_mse = mean_squared_error(y, predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune Models\n",
    "Notes:  \n",
    "- You will want to use as much data as possible for this step, especially as you move toward the end of fine-tuning.   \n",
    "- As always automate what you can.    \n",
    "\n",
    "1. Fine-tune the hyperparameters using cross-validation.  \n",
    "    - Treat your data transformation choices as hyperparameters, especially when you are not sure about them (e.g., should I replace missing values with zero or the median value? Or just drop the rows?).  \n",
    "    - Unless there are very few hyperparamter values to explore, prefer random search over grid search. If training is very long, you may prefer a Bayesian optimization approach (e.g., using a Gaussian process priors, as described by Jasper Snoek, Hugo Larochelle, and Ryan Adams ([https://goo.gl/PEFfGr](https://goo.gl/PEFfGr)))  \n",
    "2. Try Ensemble methods. Combining your best models will often perform better than running them invdividually.  \n",
    "3. Once you are confident about your final model, measure its performance on the test set to estimate the generalization error.\n",
    "\n",
    "> Don't tweak your model after measuring the generalization error: you would just start overfitting the test set.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, X, y,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.4084185  0.42835294 0.41650678 0.43798005 0.35736935 0.41668058\n",
      " 0.40241342 0.433374   0.41668058 0.40551293]\n",
      "Mean: 0.4123289121424514\n",
      "Standard deviation: 0.021432669823743727\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [44.05198777  4.24138078  0.47003993  0.47857281  0.47180457  0.48343756\n",
      "  8.48749687  0.47152107  0.46517377  0.47540826]\n",
      "Mean: 6.0096823390914444\n",
      "Standard deviation: 12.926765779469424\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, X, y,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12185290657641899"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = forest_reg.predict(X)\n",
    "forest_mse = mean_squared_error(y, predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.29342247 0.27884846 0.29653265 0.29994439 0.26977701 0.28388845\n",
      " 0.28605602 0.2848278  0.28216312 0.29566992]\n",
      "Mean: 0.28711302950769074\n",
      "Standard deviation: 0.0088118234129887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, X, y,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      6.009682\n",
       "std      13.626008\n",
       "min       0.465174\n",
       "25%       0.471592\n",
       "50%       0.476991\n",
       "75%       3.301895\n",
       "max      44.051988\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "pd.Series(np.sqrt(-scores)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.85777625490357"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(X,y)\n",
    "predictions = svm_reg.predict(X)\n",
    "svm_mse = mean_squared_error(y, predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6657759960396115"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmc_reg = SVC()\n",
    "svmc_reg.fit(X,y)\n",
    "predictions = svmc_reg.predict(X)\n",
    "svmc_mse = mean_squared_error(y, predictions)\n",
    "svmc_rmse = np.sqrt(svmc_mse)\n",
    "svmc_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09795982937354743"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_reg = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_reg.fit(X,y)\n",
    "predictions = knn_reg.predict(X)\n",
    "knn_mse = mean_squared_error(y, predictions)\n",
    "knn_rmse = np.sqrt(knn_mse)\n",
    "knn_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=3, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
       "                          'n_neighbors': [3, 4, 5, 6, 7]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 15 (53) combinations of hyperparameters\n",
    "    {'n_neighbors': [3,4,5,6,7], 'algorithm':[\"ball_tree\", \"kd_tree\", \"brute\"]}       \n",
    "  ]\n",
    "\n",
    "knn_grid_search = GridSearchCV(knn_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "knn_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'ball_tree', 'n_neighbors': 3}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1878747943931966 {'algorithm': 'ball_tree', 'n_neighbors': 3}\n",
      "0.2104967080479983 {'algorithm': 'ball_tree', 'n_neighbors': 4}\n",
      "0.2079044958036596 {'algorithm': 'ball_tree', 'n_neighbors': 5}\n",
      "0.2245003410228355 {'algorithm': 'ball_tree', 'n_neighbors': 6}\n",
      "0.220184227079956 {'algorithm': 'ball_tree', 'n_neighbors': 7}\n",
      "0.1878747943931966 {'algorithm': 'kd_tree', 'n_neighbors': 3}\n",
      "0.2104967080479983 {'algorithm': 'kd_tree', 'n_neighbors': 4}\n",
      "0.2079044958036596 {'algorithm': 'kd_tree', 'n_neighbors': 5}\n",
      "0.2245003410228355 {'algorithm': 'kd_tree', 'n_neighbors': 6}\n",
      "0.220184227079956 {'algorithm': 'kd_tree', 'n_neighbors': 7}\n"
     ]
    }
   ],
   "source": [
    "cvres = knn_grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 3}</td>\n",
       "      <td>-0.034627</td>\n",
       "      <td>-0.035878</td>\n",
       "      <td>-0.037130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035297</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011265</td>\n",
       "      <td>-0.013247</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.011994</td>\n",
       "      <td>-0.011974</td>\n",
       "      <td>0.000677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.265168</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>4</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 4}</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>-0.046308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044309</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.020549</td>\n",
       "      <td>-0.021279</td>\n",
       "      <td>-0.021487</td>\n",
       "      <td>-0.021592</td>\n",
       "      <td>-0.019921</td>\n",
       "      <td>-0.020965</td>\n",
       "      <td>0.000637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.274052</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5}</td>\n",
       "      <td>-0.041302</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>-0.047559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043224</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.022009</td>\n",
       "      <td>-0.020549</td>\n",
       "      <td>-0.019714</td>\n",
       "      <td>-0.020757</td>\n",
       "      <td>-0.019816</td>\n",
       "      <td>-0.020569</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009266</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.271985</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>6</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 6}</td>\n",
       "      <td>-0.049645</td>\n",
       "      <td>-0.051731</td>\n",
       "      <td>-0.053400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050400</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.029519</td>\n",
       "      <td>-0.028476</td>\n",
       "      <td>-0.030562</td>\n",
       "      <td>-0.028059</td>\n",
       "      <td>-0.028995</td>\n",
       "      <td>-0.029122</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.275611</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 7}</td>\n",
       "      <td>-0.043805</td>\n",
       "      <td>-0.050480</td>\n",
       "      <td>-0.055069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048481</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.030562</td>\n",
       "      <td>-0.028267</td>\n",
       "      <td>-0.030458</td>\n",
       "      <td>-0.029102</td>\n",
       "      <td>-0.028056</td>\n",
       "      <td>-0.029289</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.115812</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 3}</td>\n",
       "      <td>-0.034627</td>\n",
       "      <td>-0.035878</td>\n",
       "      <td>-0.037130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035297</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011265</td>\n",
       "      <td>-0.013247</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.011994</td>\n",
       "      <td>-0.011974</td>\n",
       "      <td>0.000677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.125431</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>4</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 4}</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>-0.046308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044309</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.020549</td>\n",
       "      <td>-0.021279</td>\n",
       "      <td>-0.021487</td>\n",
       "      <td>-0.021592</td>\n",
       "      <td>-0.019921</td>\n",
       "      <td>-0.020965</td>\n",
       "      <td>0.000637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.011965</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.130879</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 5}</td>\n",
       "      <td>-0.041302</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>-0.047559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043224</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.022009</td>\n",
       "      <td>-0.020549</td>\n",
       "      <td>-0.019714</td>\n",
       "      <td>-0.020757</td>\n",
       "      <td>-0.019816</td>\n",
       "      <td>-0.020569</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.012151</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.139140</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>6</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 6}</td>\n",
       "      <td>-0.049645</td>\n",
       "      <td>-0.051731</td>\n",
       "      <td>-0.053400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050400</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.029519</td>\n",
       "      <td>-0.028476</td>\n",
       "      <td>-0.030562</td>\n",
       "      <td>-0.028059</td>\n",
       "      <td>-0.028995</td>\n",
       "      <td>-0.029122</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.147276</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 7}</td>\n",
       "      <td>-0.043805</td>\n",
       "      <td>-0.050480</td>\n",
       "      <td>-0.055069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048481</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.030562</td>\n",
       "      <td>-0.028267</td>\n",
       "      <td>-0.030458</td>\n",
       "      <td>-0.029102</td>\n",
       "      <td>-0.028056</td>\n",
       "      <td>-0.029289</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.292479</td>\n",
       "      <td>0.066561</td>\n",
       "      <td>brute</td>\n",
       "      <td>3</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 3}</td>\n",
       "      <td>-0.034627</td>\n",
       "      <td>-0.035878</td>\n",
       "      <td>-0.037130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035297</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011265</td>\n",
       "      <td>-0.013247</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.011994</td>\n",
       "      <td>-0.011974</td>\n",
       "      <td>0.000677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.345825</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>brute</td>\n",
       "      <td>4</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 4}</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>-0.046308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044309</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.020549</td>\n",
       "      <td>-0.021279</td>\n",
       "      <td>-0.021487</td>\n",
       "      <td>-0.021592</td>\n",
       "      <td>-0.019921</td>\n",
       "      <td>-0.020965</td>\n",
       "      <td>0.000637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.357255</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 5}</td>\n",
       "      <td>-0.041302</td>\n",
       "      <td>-0.045056</td>\n",
       "      <td>-0.047559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043224</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.022009</td>\n",
       "      <td>-0.020549</td>\n",
       "      <td>-0.019714</td>\n",
       "      <td>-0.020757</td>\n",
       "      <td>-0.019816</td>\n",
       "      <td>-0.020569</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.349928</td>\n",
       "      <td>0.011116</td>\n",
       "      <td>brute</td>\n",
       "      <td>6</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 6}</td>\n",
       "      <td>-0.049645</td>\n",
       "      <td>-0.051731</td>\n",
       "      <td>-0.053400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050400</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.029519</td>\n",
       "      <td>-0.028476</td>\n",
       "      <td>-0.030562</td>\n",
       "      <td>-0.028059</td>\n",
       "      <td>-0.028995</td>\n",
       "      <td>-0.029122</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.359772</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>brute</td>\n",
       "      <td>7</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 7}</td>\n",
       "      <td>-0.043805</td>\n",
       "      <td>-0.050480</td>\n",
       "      <td>-0.055069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048481</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.030562</td>\n",
       "      <td>-0.028267</td>\n",
       "      <td>-0.030458</td>\n",
       "      <td>-0.029102</td>\n",
       "      <td>-0.028056</td>\n",
       "      <td>-0.029289</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.011094      0.003859         0.257812        0.007149   \n",
       "1        0.009216      0.000410         0.265168        0.011969   \n",
       "2        0.009540      0.000290         0.274052        0.003707   \n",
       "3        0.009266      0.000341         0.271985        0.004715   \n",
       "4        0.009467      0.000576         0.275611        0.004026   \n",
       "5        0.012573      0.000989         0.115812        0.003781   \n",
       "6        0.012073      0.000354         0.125431        0.006622   \n",
       "7        0.011965      0.000126         0.130879        0.004220   \n",
       "8        0.012151      0.000279         0.139140        0.004573   \n",
       "9        0.012319      0.000372         0.147276        0.004335   \n",
       "10       0.002180      0.000316         0.292479        0.066561   \n",
       "11       0.002453      0.000704         0.345825        0.010300   \n",
       "12       0.002214      0.000147         0.357255        0.013702   \n",
       "13       0.002061      0.000138         0.349928        0.011116   \n",
       "14       0.002479      0.000568         0.359772        0.026064   \n",
       "\n",
       "   param_algorithm param_n_neighbors  \\\n",
       "0        ball_tree                 3   \n",
       "1        ball_tree                 4   \n",
       "2        ball_tree                 5   \n",
       "3        ball_tree                 6   \n",
       "4        ball_tree                 7   \n",
       "5          kd_tree                 3   \n",
       "6          kd_tree                 4   \n",
       "7          kd_tree                 5   \n",
       "8          kd_tree                 6   \n",
       "9          kd_tree                 7   \n",
       "10           brute                 3   \n",
       "11           brute                 4   \n",
       "12           brute                 5   \n",
       "13           brute                 6   \n",
       "14           brute                 7   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "0   {'algorithm': 'ball_tree', 'n_neighbors': 3}          -0.034627   \n",
       "1   {'algorithm': 'ball_tree', 'n_neighbors': 4}          -0.042553   \n",
       "2   {'algorithm': 'ball_tree', 'n_neighbors': 5}          -0.041302   \n",
       "3   {'algorithm': 'ball_tree', 'n_neighbors': 6}          -0.049645   \n",
       "4   {'algorithm': 'ball_tree', 'n_neighbors': 7}          -0.043805   \n",
       "5     {'algorithm': 'kd_tree', 'n_neighbors': 3}          -0.034627   \n",
       "6     {'algorithm': 'kd_tree', 'n_neighbors': 4}          -0.042553   \n",
       "7     {'algorithm': 'kd_tree', 'n_neighbors': 5}          -0.041302   \n",
       "8     {'algorithm': 'kd_tree', 'n_neighbors': 6}          -0.049645   \n",
       "9     {'algorithm': 'kd_tree', 'n_neighbors': 7}          -0.043805   \n",
       "10      {'algorithm': 'brute', 'n_neighbors': 3}          -0.034627   \n",
       "11      {'algorithm': 'brute', 'n_neighbors': 4}          -0.042553   \n",
       "12      {'algorithm': 'brute', 'n_neighbors': 5}          -0.041302   \n",
       "13      {'algorithm': 'brute', 'n_neighbors': 6}          -0.049645   \n",
       "14      {'algorithm': 'brute', 'n_neighbors': 7}          -0.043805   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0           -0.035878          -0.037130  ...        -0.035297   \n",
       "1           -0.045056          -0.046308  ...        -0.044309   \n",
       "2           -0.045056          -0.047559  ...        -0.043224   \n",
       "3           -0.051731          -0.053400  ...        -0.050400   \n",
       "4           -0.050480          -0.055069  ...        -0.048481   \n",
       "5           -0.035878          -0.037130  ...        -0.035297   \n",
       "6           -0.045056          -0.046308  ...        -0.044309   \n",
       "7           -0.045056          -0.047559  ...        -0.043224   \n",
       "8           -0.051731          -0.053400  ...        -0.050400   \n",
       "9           -0.050480          -0.055069  ...        -0.048481   \n",
       "10          -0.035878          -0.037130  ...        -0.035297   \n",
       "11          -0.045056          -0.046308  ...        -0.044309   \n",
       "12          -0.045056          -0.047559  ...        -0.043224   \n",
       "13          -0.051731          -0.053400  ...        -0.050400   \n",
       "14          -0.050480          -0.055069  ...        -0.048481   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.001134                1           -0.011265           -0.013247   \n",
       "1         0.001831                7           -0.020549           -0.021279   \n",
       "2         0.002897                4           -0.022009           -0.020549   \n",
       "3         0.001888               13           -0.029519           -0.028476   \n",
       "4         0.003941               10           -0.030562           -0.028267   \n",
       "5         0.001134                1           -0.011265           -0.013247   \n",
       "6         0.001831                7           -0.020549           -0.021279   \n",
       "7         0.002897                4           -0.022009           -0.020549   \n",
       "8         0.001888               13           -0.029519           -0.028476   \n",
       "9         0.003941               10           -0.030562           -0.028267   \n",
       "10        0.001134                1           -0.011265           -0.013247   \n",
       "11        0.001831                7           -0.020549           -0.021279   \n",
       "12        0.002897                4           -0.022009           -0.020549   \n",
       "13        0.001888               13           -0.029519           -0.028476   \n",
       "14        0.003941               10           -0.030562           -0.028267   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            -0.011682           -0.011682           -0.011994   \n",
       "1            -0.021487           -0.021592           -0.019921   \n",
       "2            -0.019714           -0.020757           -0.019816   \n",
       "3            -0.030562           -0.028059           -0.028995   \n",
       "4            -0.030458           -0.029102           -0.028056   \n",
       "5            -0.011682           -0.011682           -0.011994   \n",
       "6            -0.021487           -0.021592           -0.019921   \n",
       "7            -0.019714           -0.020757           -0.019816   \n",
       "8            -0.030562           -0.028059           -0.028995   \n",
       "9            -0.030458           -0.029102           -0.028056   \n",
       "10           -0.011682           -0.011682           -0.011994   \n",
       "11           -0.021487           -0.021592           -0.019921   \n",
       "12           -0.019714           -0.020757           -0.019816   \n",
       "13           -0.030562           -0.028059           -0.028995   \n",
       "14           -0.030458           -0.029102           -0.028056   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0          -0.011974         0.000677  \n",
       "1          -0.020965         0.000637  \n",
       "2          -0.020569         0.000825  \n",
       "3          -0.029122         0.000871  \n",
       "4          -0.029289         0.001057  \n",
       "5          -0.011974         0.000677  \n",
       "6          -0.020965         0.000637  \n",
       "7          -0.020569         0.000825  \n",
       "8          -0.029122         0.000871  \n",
       "9          -0.029289         0.001057  \n",
       "10         -0.011974         0.000677  \n",
       "11         -0.020965         0.000637  \n",
       "12         -0.020569         0.000825  \n",
       "13         -0.029122         0.000871  \n",
       "14         -0.029289         0.001057  \n",
       "\n",
       "[15 rows x 22 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=42,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (34) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (23) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 30}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=6, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=30, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36080856939673256 {'max_features': 2, 'n_estimators': 3}\n",
      "0.3083845893518983 {'max_features': 2, 'n_estimators': 10}\n",
      "0.29247544850991036 {'max_features': 2, 'n_estimators': 30}\n",
      "0.3471496014863094 {'max_features': 4, 'n_estimators': 3}\n",
      "0.2942086046317213 {'max_features': 4, 'n_estimators': 10}\n",
      "0.2788557135960152 {'max_features': 4, 'n_estimators': 30}\n",
      "0.3463335578537414 {'max_features': 6, 'n_estimators': 3}\n",
      "0.29282281879465377 {'max_features': 6, 'n_estimators': 10}\n",
      "0.2767333829377463 {'max_features': 6, 'n_estimators': 30}\n",
      "0.33794682137302 {'max_features': 8, 'n_estimators': 3}\n",
      "0.29472890845329214 {'max_features': 8, 'n_estimators': 10}\n",
      "0.2775382690230212 {'max_features': 8, 'n_estimators': 30}\n",
      "0.3448988372739644 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "0.28975457650036973 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "0.3334718565197326 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "0.28088731315325133 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "0.3257510296793254 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "0.2774183376341884 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028918</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 3}</td>\n",
       "      <td>-0.128448</td>\n",
       "      <td>-0.129097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130183</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.034201</td>\n",
       "      <td>-0.035291</td>\n",
       "      <td>-0.035488</td>\n",
       "      <td>-0.035302</td>\n",
       "      <td>-0.034430</td>\n",
       "      <td>-0.034942</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083434</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 10}</td>\n",
       "      <td>-0.094172</td>\n",
       "      <td>-0.095615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095101</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.017997</td>\n",
       "      <td>-0.017724</td>\n",
       "      <td>-0.018029</td>\n",
       "      <td>-0.018037</td>\n",
       "      <td>-0.018017</td>\n",
       "      <td>-0.017961</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250750</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 30}</td>\n",
       "      <td>-0.084863</td>\n",
       "      <td>-0.087803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085542</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.013169</td>\n",
       "      <td>-0.013177</td>\n",
       "      <td>-0.013261</td>\n",
       "      <td>-0.013214</td>\n",
       "      <td>-0.013113</td>\n",
       "      <td>-0.013187</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042830</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 3}</td>\n",
       "      <td>-0.122282</td>\n",
       "      <td>-0.120614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120513</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.032845</td>\n",
       "      <td>-0.030632</td>\n",
       "      <td>-0.030898</td>\n",
       "      <td>-0.032150</td>\n",
       "      <td>-0.034291</td>\n",
       "      <td>-0.032163</td>\n",
       "      <td>0.001337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139974</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 10}</td>\n",
       "      <td>-0.087288</td>\n",
       "      <td>-0.091051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086559</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.016783</td>\n",
       "      <td>-0.016526</td>\n",
       "      <td>-0.015992</td>\n",
       "      <td>-0.016650</td>\n",
       "      <td>-0.016750</td>\n",
       "      <td>-0.016540</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.423893</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 30}</td>\n",
       "      <td>-0.077784</td>\n",
       "      <td>-0.082041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077761</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.012022</td>\n",
       "      <td>-0.011883</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>-0.012127</td>\n",
       "      <td>-0.011999</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.060015</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 3}</td>\n",
       "      <td>-0.122004</td>\n",
       "      <td>-0.129606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119947</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.030713</td>\n",
       "      <td>-0.031200</td>\n",
       "      <td>-0.030551</td>\n",
       "      <td>-0.029508</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.030951</td>\n",
       "      <td>0.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.193125</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 10}</td>\n",
       "      <td>-0.086433</td>\n",
       "      <td>-0.091773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085745</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.016107</td>\n",
       "      <td>-0.016125</td>\n",
       "      <td>-0.015901</td>\n",
       "      <td>-0.015774</td>\n",
       "      <td>-0.016254</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.578959</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 30}</td>\n",
       "      <td>-0.076058</td>\n",
       "      <td>-0.082098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076581</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011811</td>\n",
       "      <td>-0.011882</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>-0.011714</td>\n",
       "      <td>-0.011780</td>\n",
       "      <td>-0.011805</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.077204</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 3}</td>\n",
       "      <td>-0.116303</td>\n",
       "      <td>-0.119084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114208</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.031744</td>\n",
       "      <td>-0.029079</td>\n",
       "      <td>-0.030875</td>\n",
       "      <td>-0.030110</td>\n",
       "      <td>-0.031799</td>\n",
       "      <td>-0.030721</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 10}</td>\n",
       "      <td>-0.088298</td>\n",
       "      <td>-0.092945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086865</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.016853</td>\n",
       "      <td>-0.015668</td>\n",
       "      <td>-0.015972</td>\n",
       "      <td>-0.015599</td>\n",
       "      <td>-0.016280</td>\n",
       "      <td>-0.016074</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.746576</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 30}</td>\n",
       "      <td>-0.077164</td>\n",
       "      <td>-0.081724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077027</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.011917</td>\n",
       "      <td>-0.011571</td>\n",
       "      <td>-0.011476</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.011696</td>\n",
       "      <td>-0.011677</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.038551</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>-0.118806</td>\n",
       "      <td>-0.119918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118955</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.123507</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>-0.081915</td>\n",
       "      <td>-0.088598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083958</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.051115</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>-0.110833</td>\n",
       "      <td>-0.115144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111203</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.167697</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>-0.078394</td>\n",
       "      <td>-0.083484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078898</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.063085</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>-0.112687</td>\n",
       "      <td>-0.106198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106114</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.209857</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>-0.077789</td>\n",
       "      <td>-0.079983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076961</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.028918      0.004384         0.001632        0.000187   \n",
       "1        0.083434      0.000992         0.003273        0.000143   \n",
       "2        0.250750      0.004017         0.008346        0.000201   \n",
       "3        0.042830      0.000545         0.001569        0.000078   \n",
       "4        0.139974      0.003592         0.003350        0.000249   \n",
       "5        0.423893      0.004415         0.007929        0.000255   \n",
       "6        0.060015      0.000984         0.001477        0.000027   \n",
       "7        0.193125      0.001681         0.003087        0.000078   \n",
       "8        0.578959      0.005888         0.007626        0.000179   \n",
       "9        0.077204      0.001405         0.001541        0.000103   \n",
       "10       0.249050      0.001302         0.003144        0.000106   \n",
       "11       0.746576      0.009409         0.007871        0.000782   \n",
       "12       0.038551      0.000748         0.001576        0.000083   \n",
       "13       0.123507      0.000692         0.003447        0.000060   \n",
       "14       0.051115      0.001130         0.001659        0.000217   \n",
       "15       0.167697      0.002425         0.003356        0.000076   \n",
       "16       0.063085      0.000438         0.001576        0.000106   \n",
       "17       0.209857      0.001738         0.003297        0.000103   \n",
       "\n",
       "   param_max_features param_n_estimators param_bootstrap  \\\n",
       "0                   2                  3             NaN   \n",
       "1                   2                 10             NaN   \n",
       "2                   2                 30             NaN   \n",
       "3                   4                  3             NaN   \n",
       "4                   4                 10             NaN   \n",
       "5                   4                 30             NaN   \n",
       "6                   6                  3             NaN   \n",
       "7                   6                 10             NaN   \n",
       "8                   6                 30             NaN   \n",
       "9                   8                  3             NaN   \n",
       "10                  8                 10             NaN   \n",
       "11                  8                 30             NaN   \n",
       "12                  2                  3           False   \n",
       "13                  2                 10           False   \n",
       "14                  3                  3           False   \n",
       "15                  3                 10           False   \n",
       "16                  4                  3           False   \n",
       "17                  4                 10           False   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0              {'max_features': 2, 'n_estimators': 3}          -0.128448   \n",
       "1             {'max_features': 2, 'n_estimators': 10}          -0.094172   \n",
       "2             {'max_features': 2, 'n_estimators': 30}          -0.084863   \n",
       "3              {'max_features': 4, 'n_estimators': 3}          -0.122282   \n",
       "4             {'max_features': 4, 'n_estimators': 10}          -0.087288   \n",
       "5             {'max_features': 4, 'n_estimators': 30}          -0.077784   \n",
       "6              {'max_features': 6, 'n_estimators': 3}          -0.122004   \n",
       "7             {'max_features': 6, 'n_estimators': 10}          -0.086433   \n",
       "8             {'max_features': 6, 'n_estimators': 30}          -0.076058   \n",
       "9              {'max_features': 8, 'n_estimators': 3}          -0.116303   \n",
       "10            {'max_features': 8, 'n_estimators': 10}          -0.088298   \n",
       "11            {'max_features': 8, 'n_estimators': 30}          -0.077164   \n",
       "12  {'bootstrap': False, 'max_features': 2, 'n_est...          -0.118806   \n",
       "13  {'bootstrap': False, 'max_features': 2, 'n_est...          -0.081915   \n",
       "14  {'bootstrap': False, 'max_features': 3, 'n_est...          -0.110833   \n",
       "15  {'bootstrap': False, 'max_features': 3, 'n_est...          -0.078394   \n",
       "16  {'bootstrap': False, 'max_features': 4, 'n_est...          -0.112687   \n",
       "17  {'bootstrap': False, 'max_features': 4, 'n_est...          -0.077789   \n",
       "\n",
       "    split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           -0.129097  ...        -0.130183        0.002184               18   \n",
       "1           -0.095615  ...        -0.095101        0.001805               11   \n",
       "2           -0.087803  ...        -0.085542        0.001313                7   \n",
       "3           -0.120614  ...        -0.120513        0.002697               17   \n",
       "4           -0.091051  ...        -0.086559        0.003005                9   \n",
       "5           -0.082041  ...        -0.077761        0.002467                4   \n",
       "6           -0.129606  ...        -0.119947        0.005694               16   \n",
       "7           -0.091773  ...        -0.085745        0.003558                8   \n",
       "8           -0.082098  ...        -0.076581        0.002950                1   \n",
       "9           -0.119084  ...        -0.114208        0.004745               14   \n",
       "10          -0.092945  ...        -0.086865        0.004113               10   \n",
       "11          -0.081724  ...        -0.077027        0.002786                3   \n",
       "12          -0.119918  ...        -0.118955        0.002785               15   \n",
       "13          -0.088598  ...        -0.083958        0.002568                6   \n",
       "14          -0.115144  ...        -0.111203        0.003130               13   \n",
       "15          -0.083484  ...        -0.078898        0.002552                5   \n",
       "16          -0.106198  ...        -0.106114        0.004240               12   \n",
       "17          -0.079983  ...        -0.076961        0.002234                2   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            -0.034201           -0.035291           -0.035488   \n",
       "1            -0.017997           -0.017724           -0.018029   \n",
       "2            -0.013169           -0.013177           -0.013261   \n",
       "3            -0.032845           -0.030632           -0.030898   \n",
       "4            -0.016783           -0.016526           -0.015992   \n",
       "5            -0.012022           -0.011883           -0.011647   \n",
       "6            -0.030713           -0.031200           -0.030551   \n",
       "7            -0.016107           -0.016125           -0.015901   \n",
       "8            -0.011811           -0.011882           -0.011840   \n",
       "9            -0.031744           -0.029079           -0.030875   \n",
       "10           -0.016853           -0.015668           -0.015972   \n",
       "11           -0.011917           -0.011571           -0.011476   \n",
       "12           -0.000000           -0.000000           -0.000000   \n",
       "13           -0.000000           -0.000000           -0.000000   \n",
       "14           -0.000000           -0.000000           -0.000000   \n",
       "15           -0.000000           -0.000000           -0.000000   \n",
       "16           -0.000000           -0.000000           -0.000000   \n",
       "17           -0.000000           -0.000000           -0.000000   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            -0.035302           -0.034430         -0.034942         0.000522  \n",
       "1            -0.018037           -0.018017         -0.017961         0.000119  \n",
       "2            -0.013214           -0.013113         -0.013187         0.000049  \n",
       "3            -0.032150           -0.034291         -0.032163         0.001337  \n",
       "4            -0.016650           -0.016750         -0.016540         0.000288  \n",
       "5            -0.012316           -0.012127         -0.011999         0.000226  \n",
       "6            -0.029508           -0.032784         -0.030951         0.001070  \n",
       "7            -0.015774           -0.016254         -0.016032         0.000171  \n",
       "8            -0.011714           -0.011780         -0.011805         0.000057  \n",
       "9            -0.030110           -0.031799         -0.030721         0.001030  \n",
       "10           -0.015599           -0.016280         -0.016074         0.000458  \n",
       "11           -0.011726           -0.011696         -0.011677         0.000150  \n",
       "12           -0.000000           -0.000000          0.000000         0.000000  \n",
       "13           -0.000000           -0.000000          0.000000         0.000000  \n",
       "14           -0.000000           -0.000000          0.000000         0.000000  \n",
       "15           -0.000000           -0.000000          0.000000         0.000000  \n",
       "16           -0.000000           -0.000000          0.000000         0.000000  \n",
       "17           -0.000000           -0.000000          0.000000         0.000000  \n",
       "\n",
       "[18 rows x 23 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                                                   warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e8a602dd8>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e45b614a8>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26857561305381306 {'max_features': 7, 'n_estimators': 180}\n",
      "0.2854897150164131 {'max_features': 5, 'n_estimators': 15}\n",
      "0.2777437177056502 {'max_features': 3, 'n_estimators': 72}\n",
      "0.28062001884057536 {'max_features': 5, 'n_estimators': 21}\n",
      "0.26904657823896627 {'max_features': 7, 'n_estimators': 122}\n",
      "0.2778523485922044 {'max_features': 3, 'n_estimators': 75}\n",
      "0.27723473507242946 {'max_features': 3, 'n_estimators': 88}\n",
      "0.27105847996154275 {'max_features': 5, 'n_estimators': 100}\n",
      "0.2762857673511324 {'max_features': 3, 'n_estimators': 150}\n",
      "0.37818492044191454 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07610476, 0.09300435, 0.05268591, 0.05804585, 0.05177924,\n",
       "       0.11296761, 0.12336569, 0.0576925 , 0.03801245, 0.05363324,\n",
       "       0.05597064, 0.06124968, 0.08618211, 0.07930597])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12336568959196602, 'V7'),\n",
       " (0.11296761034415888, 'V6'),\n",
       " (0.09300434577388984, 'V2'),\n",
       " (0.08618211474742397, 'V13'),\n",
       " (0.07930596979622853, 'V14'),\n",
       " (0.07610476127163278, 'V1'),\n",
       " (0.061249676331755425, 'V12'),\n",
       " (0.05804584669680661, 'V4'),\n",
       " (0.057692496964609485, 'V8'),\n",
       " (0.055970640815121576, 'V11'),\n",
       " (0.05363324466323962, 'V10'),\n",
       " (0.05268590753344825, 'V3'),\n",
       " (0.051779242822978626, 'V5'),\n",
       " (0.03801245264674041, 'V9')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(feature_importances, list(data.columns) ), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present Solution\n",
    "1. Document what you have done.  \n",
    "2. Create a nice presentation.  \n",
    "    - Make sure you highlight the big picture first.  \n",
    "3. Explain why your solution achieves the business objective.  \n",
    "4. Don't forget to present interesting points you noticed along the way.  \n",
    "    - Describe what worked and what did not.  \n",
    "    - List your assumptions and your system's limitations.  \n",
    "5. Ensure your key findings are communicated through beautiful visualizations or easy-to-remember statements (e.g., \"the median income is the number-one predictor of housing prices\").  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch and Monitor\n",
    "1. Get your solution ready for production (plug into production data inputs, write unit tests, etc.).  \n",
    "2. Write monitoring code to check your system's live performance at regular intervals and trigger alerts when it drops.  \n",
    "    - Beware of slow degradation too: models tend to \"rot\" as data evolves.   \n",
    "    - Measuring performance may require a human pipeline (e.g., via a crowdsourcing service).  \n",
    "    - Also monitor your inputs' quality (e.g., a malfunctioning sensor sending random values, or another team's output becoming stale). This is  particulary important for online learning systems.  \n",
    "3. Retrain your models on a regular basis on fresh data (automate as much as possible).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
